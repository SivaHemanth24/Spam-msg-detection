{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-06T15:31:26.936347Z","iopub.execute_input":"2021-06-06T15:31:26.936671Z","iopub.status.idle":"2021-06-06T15:31:26.941139Z","shell.execute_reply.started":"2021-06-06T15:31:26.936641Z","shell.execute_reply":"2021-06-06T15:31:26.940334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/sms-spam-collection-dataset/spam.csv\", encoding='latin-1')","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:31:26.942571Z","iopub.execute_input":"2021-06-06T15:31:26.943345Z","iopub.status.idle":"2021-06-06T15:31:26.971393Z","shell.execute_reply.started":"2021-06-06T15:31:26.943307Z","shell.execute_reply":"2021-06-06T15:31:26.970667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=data[['v1','v2']]","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:31:26.97337Z","iopub.execute_input":"2021-06-06T15:31:26.973723Z","iopub.status.idle":"2021-06-06T15:31:26.978883Z","shell.execute_reply.started":"2021-06-06T15:31:26.973686Z","shell.execute_reply":"2021-06-06T15:31:26.978049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.rename(columns={\"v1\": \"label\", \"v2\": \"msg\"},inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:31:26.980672Z","iopub.execute_input":"2021-06-06T15:31:26.981331Z","iopub.status.idle":"2021-06-06T15:31:26.98821Z","shell.execute_reply.started":"2021-06-06T15:31:26.981244Z","shell.execute_reply":"2021-06-06T15:31:26.987213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:31:26.989604Z","iopub.execute_input":"2021-06-06T15:31:26.990123Z","iopub.status.idle":"2021-06-06T15:31:27.004701Z","shell.execute_reply.started":"2021-06-06T15:31:26.990084Z","shell.execute_reply":"2021-06-06T15:31:27.00369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts=data['msg'].tolist()\nlabels=data['label'].tolist()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:31:27.006122Z","iopub.execute_input":"2021-06-06T15:31:27.006496Z","iopub.status.idle":"2021-06-06T15:31:27.011863Z","shell.execute_reply.started":"2021-06-06T15:31:27.006461Z","shell.execute_reply":"2021-06-06T15:31:27.010728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels=[ 0 if i==\"ham\" else 1 for i in labels]","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:31:27.013506Z","iopub.execute_input":"2021-06-06T15:31:27.014077Z","iopub.status.idle":"2021-06-06T15:31:27.020712Z","shell.execute_reply.started":"2021-06-06T15:31:27.014005Z","shell.execute_reply":"2021-06-06T15:31:27.019671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=.3,stratify=labels)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:31:27.022303Z","iopub.execute_input":"2021-06-06T15:31:27.022767Z","iopub.status.idle":"2021-06-06T15:31:27.038466Z","shell.execute_reply.started":"2021-06-06T15:31:27.022729Z","shell.execute_reply":"2021-06-06T15:31:27.037563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_texts, val_texts, test_labels, val_labels = train_test_split(val_texts, val_labels, test_size=.5,stratify=val_labels)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:31:27.040835Z","iopub.execute_input":"2021-06-06T15:31:27.041212Z","iopub.status.idle":"2021-06-06T15:31:27.051013Z","shell.execute_reply.started":"2021-06-06T15:31:27.041174Z","shell.execute_reply":"2021-06-06T15:31:27.050056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_size=len(train_texts)\nval_size=len(val_texts)\ntest_size=len(test_texts)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:31:27.192145Z","iopub.execute_input":"2021-06-06T15:31:27.192542Z","iopub.status.idle":"2021-06-06T15:31:27.197576Z","shell.execute_reply.started":"2021-06-06T15:31:27.192498Z","shell.execute_reply":"2021-06-06T15:31:27.196558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:31:27.199486Z","iopub.execute_input":"2021-06-06T15:31:27.199894Z","iopub.status.idle":"2021-06-06T15:31:32.637735Z","shell.execute_reply.started":"2021-06-06T15:31:27.199858Z","shell.execute_reply":"2021-06-06T15:31:32.636845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DistilBertTokenizerFast\ntokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:31:32.639749Z","iopub.execute_input":"2021-06-06T15:31:32.640028Z","iopub.status.idle":"2021-06-06T15:31:36.091011Z","shell.execute_reply.started":"2021-06-06T15:31:32.64Z","shell.execute_reply":"2021-06-06T15:31:36.090021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_encodings = tokenizer(train_texts, truncation=True, padding=True)\nval_encodings = tokenizer(val_texts, truncation=True, padding=True)\ntest_encodings = tokenizer(test_texts, truncation=True, padding=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:31:36.092677Z","iopub.execute_input":"2021-06-06T15:31:36.093065Z","iopub.status.idle":"2021-06-06T15:31:36.778903Z","shell.execute_reply.started":"2021-06-06T15:31:36.093025Z","shell.execute_reply":"2021-06-06T15:31:36.77804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nclass SMSDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = SMSDataset(train_encodings, train_labels)\nval_dataset = SMSDataset(val_encodings, val_labels)\ntest_dataset = SMSDataset(test_encodings, test_labels)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:31:36.780237Z","iopub.execute_input":"2021-06-06T15:31:36.780572Z","iopub.status.idle":"2021-06-06T15:31:37.833951Z","shell.execute_reply.started":"2021-06-06T15:31:36.780538Z","shell.execute_reply":"2021-06-06T15:31:37.833004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom torch.utils.data import DataLoader\nfrom transformers import DistilBertForSequenceClassification, AdamW\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\nmodel = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:31:37.835221Z","iopub.execute_input":"2021-06-06T15:31:37.835558Z","iopub.status.idle":"2021-06-06T15:31:57.731554Z","shell.execute_reply.started":"2021-06-06T15:31:37.835522Z","shell.execute_reply":"2021-06-06T15:31:57.730741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nvalidation_dataloader= DataLoader(val_dataset, batch_size=16, shuffle=True)\n\n\noptim = AdamW(model.parameters(), lr=5e-5)\n\nfor epoch in tqdm(range(5)):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    for batch in train_loader:\n        optim.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs[0]\n        loss.backward()\n        optim.step()\n        \n        running_loss += loss.item()\n        predictions = outputs.logits.argmax(-1)\n        correct += (predictions == labels).float().sum()\n        \n        \n    print(\"Loss:\", running_loss / batch[\"input_ids\"].shape[0])\n    accuracy = 100 * correct / train_size\n    print(\"Training accuracy:\", accuracy.item())\n    \n    \n    \n    model.eval()\n\n    correct = 0\n    for batch in validation_dataloader:\n  \n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs[0]\n        \n        running_loss += loss.item()\n        predictions = outputs.logits.argmax(-1)\n        correct += (predictions == labels).float().sum()\n        \n        \n    print(\"Loss:\", running_loss / batch[\"input_ids\"].shape[0])\n    accuracy = 100 * correct / val_size\n    print(\"validation accuracy:\", accuracy.item())\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:31:57.735255Z","iopub.execute_input":"2021-06-06T15:31:57.737183Z","iopub.status.idle":"2021-06-06T15:36:15.007631Z","shell.execute_reply.started":"2021-06-06T15:31:57.737142Z","shell.execute_reply":"2021-06-06T15:36:15.006781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataloader= DataLoader(test_dataset, batch_size=16, shuffle=True)\ncorrect = 0\nmodel.eval()\n\nfor batch in test_dataloader:\n\n    input_ids = batch['input_ids'].to(device)\n    attention_mask = batch['attention_mask'].to(device)\n    labels = batch['labels'].to(device)\n    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n    loss = outputs[0]\n\n    running_loss += loss.item()\n    predictions = outputs.logits.argmax(-1)\n    correct += (predictions == labels).float().sum()\n\n\nprint(\"Loss:\", running_loss / batch[\"input_ids\"].shape[0])\naccuracy = 100 * correct / val_size\nprint(\"test accuracy:\", accuracy.item())","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:36:15.009166Z","iopub.execute_input":"2021-06-06T15:36:15.009743Z","iopub.status.idle":"2021-06-06T15:36:17.970952Z","shell.execute_reply.started":"2021-06-06T15:36:15.009699Z","shell.execute_reply":"2021-06-06T15:36:17.969992Z"},"trusted":true},"execution_count":null,"outputs":[]}]}